{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d109275-5919-4e29-8432-a6f479d32880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load the original dataset\n",
    "try:\n",
    "    df = pd.read_csv('food_nutrient_temperament.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'food_nutrient_temperament.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Preprocessing\n",
    "required_columns = ['food_ description', 'Temperament']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    print(f\"Error: Missing columns {required_columns} in DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "X = df.drop(columns=['food_ description', 'Temperament']).fillna(0)\n",
    "y = df['Temperament']\n",
    "feature_names = X.columns\n",
    "\n",
    "# Filter valid Temperament values\n",
    "valid_temperaments = [0, 1, 2]  # 0: Cold, 1: Hot, 2: Moderate\n",
    "valid_mask = df['Temperament'].isin(valid_temperaments)\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask]\n",
    "print(\"Number of valid samples:\", len(y))\n",
    "print(\"Class Distribution:\\n\", y.value_counts())\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply SMOTE\n",
    "try:\n",
    "    smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Class Distribution after SMOTE:\\n\", pd.Series(y_train_res).value_counts())\n",
    "except ValueError as e:\n",
    "    print(\"SMOTE failed:\", e)\n",
    "    X_train_res, y_train_res = X_train, y_train\n",
    "\n",
    "# Train Gradient Boosting model (using best parameters)\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42\n",
    ")\n",
    "gb.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Save the model and scaler\n",
    "with open('gb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gb, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Load new dataset (31 samples, no Temperament)\n",
    "try:\n",
    "    new_data = pd.read_csv('New data food nutrient.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'New_data.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Verify new data structure\n",
    "if 'food_ description' not in new_data.columns:\n",
    "    print(\"Error: 'food_ description' column missing in new data.\")\n",
    "    exit()\n",
    "if new_data.drop(columns=['food_ description']).shape[1] != len(feature_names):\n",
    "    print(f\"Error: New data must have the same features as original data: {feature_names.tolist()}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure new_data has the same features\n",
    "new_data = new_data[feature_names.tolist() + ['food_ description']].fillna(0)\n",
    "\n",
    "# Function to predict temperament\n",
    "def predict_temperament(new_data, model, scaler, feature_names):\n",
    "    X_new = new_data.drop(columns=['food_ description']).fillna(0)\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "    probabilities = model.predict_proba(X_new_scaled)\n",
    "    return predictions, probabilities\n",
    "\n",
    "# Function for human-in-the-loop validation\n",
    "def human_in_the_loop(new_data, model, scaler, feature_names, dataset_file='food_nutrient_temperament.csv'):\n",
    "    predictions, probabilities = predict_temperament(new_data, model, scaler, feature_names)\n",
    "    temperament_map = {0: 'Cold', 1: 'Hot', 2: 'Moderate'}\n",
    "    \n",
    "    validated_data = new_data.copy()\n",
    "    validated_temperaments = []\n",
    "    \n",
    "    for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "        food_desc = new_data.iloc[i]['food_ description']\n",
    "        pred_label = temperament_map[pred]\n",
    "        max_prob = np.max(prob) * 100\n",
    "        prob_dist = {temperament_map[j]: f\"{prob[j]*100:.2f}%\" for j in range(len(prob))}\n",
    "        \n",
    "        print(f\"\\nFood: {food_desc}\")\n",
    "        print(f\"Predicted Temperament: {pred_label} (Confidence: {max_prob:.2f}%)\")\n",
    "        print(f\"Probability Distribution: {prob_dist}\")\n",
    "        print(\"Options: [0: Cold, 1: Hot, 2: Moderate, -1: Skip]\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"Enter correct Temperament (0, 1, 2, or -1 to skip): \")\n",
    "            try:\n",
    "                user_input = int(user_input)\n",
    "                if user_input in [-1, 0, 1, 2]:\n",
    "                    break\n",
    "                print(\"Invalid input. Please enter 0, 1, 2, or -1.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number (0, 1, 2, or -1).\")\n",
    "        \n",
    "        validated_temperaments.append(user_input if user_input != -1 else None)\n",
    "    \n",
    "    # Add validated temperaments\n",
    "    validated_data['Temperament'] = validated_temperaments\n",
    "    validated_data = validated_data[validated_data['Temperament'].notnull()]\n",
    "    \n",
    "    if not validated_data.empty:\n",
    "        df_updated = pd.concat([pd.read_csv(dataset_file), validated_data], ignore_index=True)\n",
    "        df_updated.to_csv(dataset_file, index=False)\n",
    "        print(f\"\\nValidated data added to {dataset_file}. New dataset size: {len(df_updated)}\")\n",
    "    else:\n",
    "        print(\"\\nNo validated data added.\")\n",
    "    \n",
    "    return validated_data, len(validated_data)\n",
    "\n",
    "# Run human-in-the-loop validation\n",
    "validated_data, num_validated = human_in_the_loop(new_data, gb, scaler, feature_names)\n",
    "\n",
    "# Retrain model with updated dataset\n",
    "if num_validated > 0:\n",
    "    df_updated = pd.read_csv('food_nutrient_temperament.csv')\n",
    "    X_updated = df_updated.drop(columns=['food_ description', 'Temperament']).fillna(0)\n",
    "    y_updated = df_updated['Temperament']\n",
    "    valid_mask = y_updated.isin(valid_temperaments)\n",
    "    X_updated = X_updated[valid_mask]\n",
    "    y_updated = y_updated[valid_mask]\n",
    "    \n",
    "    X_updated_scaled = scaler.fit_transform(X_updated)\n",
    "    X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(\n",
    "        X_updated_scaled, y_updated, test_size=0.2, random_state=42, stratify=y_updated\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        X_train_res_up, y_train_res_up = smote.fit_resample(X_train_up, y_train_up)\n",
    "        gb.fit(X_train_res_up, y_train_res_up)\n",
    "        y_pred_up = gb.predict(X_test_up)\n",
    "        print(\"\\nUpdated Gradient Boosting Test Accuracy:\", accuracy_score(y_test_up, y_pred_up))\n",
    "        print(\"Updated Classification Report:\\n\", classification_report(y_test_up, y_pred_up, target_names=['Cold', 'Hot', 'Moderate']))\n",
    "        \n",
    "        # Save updated model\n",
    "        with open('gb_model_updated.pkl', 'wb') as f:\n",
    "            pickle.dump(gb, f)\n",
    "    except ValueError as e:\n",
    "        print(\"SMOTE failed for updated dataset:\", e)\n",
    "else:\n",
    "    print(\"\\nNo retraining performed due to no validated data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
